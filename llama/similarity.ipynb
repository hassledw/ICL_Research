{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/hassledw/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import pickle\n",
    "import torch\n",
    "# https://huggingface.co/KaiLv\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import time\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantical Embeddings\n",
    "\n",
    "1. https://huggingface.co/sentence-transformers\n",
    "2. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks https://arxiv.org/pdf/1908.10084.pdf\n",
    "3. https://www.sbert.net/docs/pretrained_models.html#model-overview\n",
    "4. https://www.sbert.net/examples/applications/semantic-search/README.html#semantic-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "(1, 384)\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sentences we want to encode. Example:\n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    "sentence2 = ['Bears are Really Cool']\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embedding = embedder.encode(sentence)\n",
    "embedding2 = embedder.encode(sentence2)\n",
    "print(embedding.shape)\n",
    "print(embedding2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_arrays(datasetname=\"KaiLv/UDR_Yelp\"):\n",
    "    '''\n",
    "    Creates the X_* and y_* arrays.\n",
    "    '''\n",
    "    dataset = load_dataset(datasetname)\n",
    "    X_train = np.array(dataset[\"train\"][\"sentence\"])\n",
    "    y_train = np.array(dataset[\"train\"][\"label\"])\n",
    "\n",
    "    X_test = np.array(dataset[\"test\"][\"sentence\"])\n",
    "    # y_test = np.array(dataset[\"test\"][\"label\"])\n",
    "\n",
    "    # X_debug = np.array(dataset[\"debug\"][\"sentence\"])\n",
    "    # y_debug = np.array(dataset[\"debug\"][\"label\"])\n",
    "    \n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed the UDR_Yelp Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 760/760 [00:00<00:00, 6.24MB/s]\n",
      "Downloading data: 100%|██████████| 9.64M/9.64M [00:00<00:00, 9.82MB/s]\n",
      "Downloading data: 100%|██████████| 268k/268k [00:00<00:00, 1.35MB/s]]\n",
      "Downloading data: 100%|██████████| 267k/267k [00:00<00:00, 1.20MB/s]]\n",
      "Downloading data: 100%|██████████| 7.65M/7.65M [00:00<00:00, 15.1MB/s]\n",
      "Downloading data files: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]\n",
      "Extracting data files: 100%|██████████| 4/4 [00:00<00:00, 484.88it/s]\n",
      "Generating train split: 100%|██████████| 131062/131062 [00:00<00:00, 573596.72 examples/s]\n",
      "Generating validation split: 100%|██████████| 3272/3272 [00:00<00:00, 415632.29 examples/s]\n",
      "Generating test split: 100%|██████████| 3262/3262 [00:00<00:00, 404225.47 examples/s]\n",
      "Generating debug split: 100%|██████████| 100000/100000 [00:00<00:00, 605647.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Corpus with example sentences\n",
    "X_train, y_train, X_test = create_data_arrays(datasetname=\"KaiLv/UDR_SNLI\")\n",
    "\n",
    "corpus = X_train\n",
    "queries = X_test\n",
    "\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True).to(device)\n",
    "corpus_embeddings = util.normalize_embeddings(corpus_embeddings)\n",
    "\n",
    "query_embeddings = embedder.encode(queries, convert_to_tensor=True).to(device)\n",
    "query_embeddings = util.normalize_embeddings(query_embeddings)\n",
    "\n",
    "hits = util.semantic_search(query_embeddings, corpus_embeddings, top_k=3, score_function=util.dot_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Top-K Examples for Every Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This church choir sings to the masses as they sing joyous songs from the book at a church. Based on that information, is the claim The church has cracks in the ceiling. \"Entailment\", \"Contradiction\", or \"Inconclusive\"?\n",
      "\t1. A choir singing in a church. Based on that information, is the claim The choir is singing a beautiful song. \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 1\n",
      "\t2. Choir in a church is singing to the crowd. Based on that information, is the claim People are singing in a church. \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 0\n",
      "\t3. A group of people are seen in a church singing under a yellow ceiling. Based on that information, is the claim The people are singing a church hymn. \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 1\n",
      "A woman with a green headscarf, blue shirt and a very big grin. Based on that information, is the claim The woman is young. \"Entailment\", \"Contradiction\", or \"Inconclusive\"?\n",
      "\t1. A middle-aged oriental woman in a green headscarf and blue shirt is flashing a giant smile. Based on that information, is the claim The middle aged oriental woman is watchingt v \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 2\n",
      "\t2. A young girl in a gray illustrated shirt is holding her hands over her head. Based on that information, is the claim There is a young man in green. \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 2\n",
      "\t3. A woman in a green shirt is holding her face. Based on that information, is the claim A woman in a green shirt \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 0\n",
      "An old man with a package poses in front of an advertisement. Based on that information, is the claim A man poses in front of an ad. \"Entailment\", \"Contradiction\", or \"Inconclusive\"?\n",
      "\t1. An old man is standing in front of an ad on the sidewalk. Based on that information, is the claim An old woman is standing in front of an ad on the sidewalk. \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 2\n",
      "\t2. A man is looking at an advertisement located at the top of a subway entrance. Based on that information, is the claim A young man is looking at an ad. \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 1\n",
      "\t3. An old man, behind him on glass is many political advertisements. Based on that information, is the claim An old man is standing in front of a ad. \"Entailment\", \"Contradiction\", or \"Inconclusive\"? = 0\n"
     ]
    }
   ],
   "source": [
    "hits = np.array(hits)\n",
    "for i, query in enumerate(hits[:3]):\n",
    "    print(X_test[i])\n",
    "    for x, top_k_entry in enumerate(query):\n",
    "        train_idx = top_k_entry[\"corpus_id\"]\n",
    "        print(f\"\\t{x + 1}. {X_train[train_idx]} = {y_train[train_idx]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./token.txt\") as f:\n",
    "    token = f.readline()\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=token)\n",
    "    model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "        load_in_8bit=False,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(prompt, max_tokens=20):\n",
    "    '''\n",
    "    Queries the llama model.\n",
    "    '''\n",
    "    inputs = tokenizer(\n",
    "        f\"{prompt}\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "    generation_config = transformers.GenerationConfig(\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_p=0.75,\n",
    "        top_k=1,\n",
    "        repetition_penalty=1.5,\n",
    "        max_new_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=torch.ones_like(input_ids),\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(\n",
    "        generation_output[0].cuda(), skip_special_tokens=True\n",
    "    ).strip()\n",
    "\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"sentence\", \"label\"])\n",
    "count = 1\n",
    "hits = np.array(hits)\n",
    "\n",
    "for i, entry in enumerate(hits):\n",
    "    query = X_test[i]\n",
    "    train_idx_1 = entry[0][\"corpus_id\"]\n",
    "    train_idx_2 = entry[1][\"corpus_id\"]\n",
    "    train_idx_3 = entry[2][\"corpus_id\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Here are some examples of my task:\n",
    "    1. {X_train[train_idx_1]} Response: {y_train[train_idx_1]}\n",
    "    2. {X_train[train_idx_2]} Response: {y_train[train_idx_2]}\n",
    "    3. {X_train[train_idx_3]} Response: {y_train[train_idx_3]}\n",
    "    rate the sentiment of the below review: \"very negative\", \"negative\", \"neutral\", \"positive\", or \"very positive\".\n",
    "    ###\\\"{query}\\\" Response: \"\"\"\n",
    "\n",
    "    output_text = query_model(prompt)\n",
    "\n",
    "    print(output_text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(f\"Finished {count}/{len(X_test)}\\n\")\n",
    "    entry = [query, output_text]\n",
    "    df_entry = pd.DataFrame(entry, index=['sentence', 'label']).T\n",
    "    df = pd.concat((df, df_entry))\n",
    "    count+=1\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "df.to_csv(f\"/home/grads/hassledw/ICL_Research/UDR_yelp_results/UDR-yelp-fewshot-llama.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Result Class to Run Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 399 \"None\" entries\n",
      "Dropped 256 \"None\" entries\n",
      "Llama-7b Prediction Accuracy (Zero-shot): 37.79%\n",
      "Llama-7b Prediction Accuracy (Few-shot): 49.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3048256/1365130721.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"label\"] = df[\"label\"].astype(int)\n",
      "/tmp/ipykernel_3048256/1365130721.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"label\"] = df[\"label\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "class YelpResults:\n",
    "    def __init__(self, zero_yelp_df, few_yelp_df):\n",
    "        self.zero_yelp_df = zero_yelp_df\n",
    "        self.few_yelp_df = few_yelp_df\n",
    "        self.truth_df = pd.read_csv(\"/home/grads/hassledw/ICL_Research/UDR_Yelp_results/UDR-yelp-llama.csv\")\n",
    "    \n",
    "    def clean_data(self, df):\n",
    "        '''\n",
    "        Cleans the data by retrieving the label and dropping None entries. \n",
    "        '''\n",
    "        def get_response_yelp(text):\n",
    "            '''\n",
    "            Cleans the text of the label to just get the response\n",
    "            '''\n",
    "            valid = [\"very negative\", \"very positive\", \"negative\", \"positive\", \"neutral\"]\n",
    "            valid_dict = {\"very negative\": 0, \"negative\": 1, \"neutral\": 2, \"positive\": 3, \"very positive\": 4}\n",
    "            sentences = text.split(\"Response:\")\n",
    "            query = sentences[-1].strip(\"##\").strip(\" \").lower()\n",
    "            \n",
    "            if len(sentences[-1].split(\" \")) > 3 or query not in valid:\n",
    "                for v in valid:\n",
    "                    if v in query:\n",
    "                        return valid_dict[v]\n",
    "                return None\n",
    "            else:\n",
    "                return valid_dict[query]\n",
    "            \n",
    "        df[\"label\"] = df[\"label\"].apply(get_response_yelp)\n",
    "        orig_entries = df.shape[0]\n",
    "        df = df.dropna()\n",
    "        print(f\"Dropped {orig_entries - df.shape[0]} \\\"None\\\" entries\")\n",
    "        df[\"label\"] = df[\"label\"].astype(int)\n",
    "        return df\n",
    "    \n",
    "    def gather_yelp_accuracy(self, df):\n",
    "        '''\n",
    "        Gets the overall accuracy of df.\n",
    "        ''' \n",
    "        df_results = pd.merge(self.truth_df, df, on=['sentence'], how='inner')\n",
    "        accurate_results = df_results[df_results[\"label_x\"] == df_results[\"label_y\"]]\n",
    "        return len(accurate_results) / len(df_results) * 100\n",
    "    \n",
    "    def run_results(self):\n",
    "        '''\n",
    "        Runs the results of the Yelp dataset. \n",
    "        '''\n",
    "        self.zero_yelp_df = self.clean_data(self.zero_yelp_df)\n",
    "        self.few_yelp_df = self.clean_data(self.few_yelp_df)\n",
    "        print(f\"Llama-7b Prediction Accuracy (Zero-shot): {self.gather_yelp_accuracy(self.zero_yelp_df):.2f}%\")\n",
    "        print(f\"Llama-7b Prediction Accuracy (Few-shot): {self.gather_yelp_accuracy(self.few_yelp_df):.2f}%\")\n",
    "        print()\n",
    "\n",
    "test_yelp_df = pd.read_csv(\"/home/grads/hassledw/ICL_Research/UDR_Yelp_results/UDR-yelp-llama.csv\")\n",
    "zero_yelp_df = pd.read_csv(\"/home/grads/hassledw/ICL_Research/UDR_Yelp_results/UDR_Yelp-zeroshot-llama.csv\")\n",
    "few_yelp_df = pd.read_csv(\"/home/grads/hassledw/ICL_Research/UDR_Yelp_results/UDR_Yelp-fewshot-llama.csv\")\n",
    "yelpres = YelpResults(zero_yelp_df, few_yelp_df)\n",
    "yelpres.run_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"KaiLv/UDR_SNLI\")\n",
    "data = dataset[\"test\"]\n",
    "\n",
    "data = pd.DataFrame(data).drop(columns=[\"idx\"])\n",
    "data.to_csv(\"/home/grads/hassledw/ICL_Research/UDR_SNLI_results/UDR-snli-llama.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 \"None\" entries\n",
      "Llama-7b Prediction Accuracy (Zero-shot): 0.00%\n",
      "Llama-7b Prediction Accuracy (Few-shot): 38.63%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SNLIResults:\n",
    "    def __init__(self, zero_snli_df, few_snli_df):\n",
    "        self.zero_snli_df = zero_snli_df\n",
    "        self.few_snli_df = few_snli_df\n",
    "        self.truth_df = pd.read_csv(\"/home/grads/hassledw/ICL_Research/UDR_SNLI_results/UDR-snli-llama.csv\")\n",
    "    \n",
    "    def clean_data(self, df):\n",
    "        '''\n",
    "        Cleans the data by retrieving the label and dropping None entries. \n",
    "        '''\n",
    "        def get_response_snli(text):\n",
    "            '''\n",
    "            Cleans the text of the label to just get the response\n",
    "            '''\n",
    "            valid = [\"entail\", \"inco\", \"contra\", \"in con\"]\n",
    "            valid_dict = {\"entailment\": 0, \"inconclusive\": 1, \"contradiction\": 2}\n",
    "\n",
    "            sentences = text.split(\"Response:\")\n",
    "            query = sentences[-1].strip(\"##\").strip(\" \").lower()\n",
    "            \n",
    "            if query not in valid:\n",
    "                for i, v in enumerate(valid):\n",
    "                    if i == 3:\n",
    "                        return valid_dict[list(valid_dict.keys())[1]]\n",
    "                    if v in query:\n",
    "                        return valid_dict[list(valid_dict.keys())[i]]\n",
    "                print(query)\n",
    "                return None\n",
    "            else:\n",
    "                return valid_dict[query]\n",
    "            \n",
    "        df[\"label\"] = df[\"label\"].apply(get_response_snli)\n",
    "        orig_entries = df.shape[0]\n",
    "        df = df.dropna()\n",
    "        print(f\"Dropped {orig_entries - df.shape[0]} \\\"None\\\" entries\")\n",
    "        df[\"label\"] = df[\"label\"].astype(int)\n",
    "        return df\n",
    "    \n",
    "    def gather_snli_accuracy(self, df):\n",
    "        '''\n",
    "        Gets the overall accuracy of df.\n",
    "        ''' \n",
    "        df_results = pd.merge(self.truth_df, df, on=['sentence'], how='inner')\n",
    "        accurate_results = df_results[df_results[\"label_x\"] == df_results[\"label_y\"]]\n",
    "        return len(accurate_results) / len(df_results) * 100\n",
    "    \n",
    "    def run_results(self):\n",
    "        '''\n",
    "        Runs the results of the Yelp dataset. \n",
    "        '''\n",
    "        self.few_snli_df = self.clean_data(self.few_snli_df)\n",
    "        print(f\"Llama-7b Prediction Accuracy (Zero-shot): {0:.2f}%\")\n",
    "        print(f\"Llama-7b Prediction Accuracy (Few-shot): {self.gather_snli_accuracy(self.few_snli_df):.2f}%\")\n",
    "        print()\n",
    "\n",
    "few_snli_df = pd.read_csv(\"/home/grads/hassledw/ICL_Research/UDR_SNLI_results/UDR_SNLI-fewshot-llama.csv\")\n",
    "yelpres = SNLIResults(None, few_snli_df)\n",
    "yelpres.run_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
